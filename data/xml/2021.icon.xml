<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.icon">
  <volume id="nlp4dh" ingest-date="2022-09-06">
    <meta>
      <booktitle>Proceedings of the Workshop on Natural Language Processing for Digital Humanities</booktitle>
      <editor><first>Mika</first><last>Hämäläinen</last></editor>
      <editor><first>Khalid</first><last>Alnajjar</last></editor>
      <editor><first>Niko</first><last>Partanen</last></editor>
      <editor><first>Jack</first><last>Rueter</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Silchar, India</address>
      <month>December</month>
      <year>2021</year>
      <url hash="b0ee8b7c">2021.icon-nlp4dh</url>
    </meta>
    <frontmatter>
      <url hash="6766ae05">2021.icon-nlp4dh.0</url>
      <bibkey>icon-2021-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Sentiment Dynamics of Success: Fractal Scaling of Story Arcs Predicts Reader Preferences</title>
      <author><first>Yuri</first><last>Bizzoni</last></author>
      <author><first>Telma</first><last>Peura</last></author>
      <author><first>Mads Rosendahl</first><last>Thomsen</last></author>
      <author><first>Kristoffer</first><last>Nielbo</last></author>
      <pages>1–6</pages>
      <abstract>e explore the correlation between the sentiment arcs of H. C. Andersen’s fairy tales and their popularity, measured as their average score on the platform GoodReads. Specifically, we do not conceive a story’s overall sentimental trend as predictive <i>per se</i>, but we focus on its coherence and predictability over time as represented by the arc’s Hurst exponent. We find that degrading Hurst values tend to imply degrading quality scores, while a Hurst exponent between .55 and .65 might indicate a “sweet spot” for literary appreciation.</abstract>
      <url hash="9e053e78">2021.icon-nlp4dh.1</url>
      <bibkey>bizzoni-etal-2021-sentiment</bibkey>
    </paper>
    <paper id="2">
      <title>The Validity of Lexicon-based Sentiment Analysis in Interdisciplinary Research</title>
      <author><first>Emily</first><last>Öhman</last></author>
      <pages>7–12</pages>
      <abstract>Lexicon-based sentiment and emotion analysis methods are widely used particularly in applied Natural Language Processing (NLP) projects in fields such as computational social science and digital humanities. These lexicon-based methods have often been criticized for their lack of validation and accuracy – sometimes fairly. However, in this paper, we argue that lexicon-based methods work well particularly when moving up in granularity and show how useful lexicon-based methods can be for projects where neither qualitative analysis nor a machine learning-based approach is possible. Indeed, we argue that the measure of a lexicon’s accuracy should be grounded in its usefulness.</abstract>
      <url hash="6e2816a3">2021.icon-nlp4dh.2</url>
      <bibkey>ohman-2021-validity</bibkey>
    </paper>
    <paper id="3">
      <title>How Does the Hate Speech Corpus Concern Sociolinguistic Discussions? A Case Study on <fixed-case>K</fixed-case>orean Online News Comments</title>
      <author><first>Won Ik</first><last>Cho</last></author>
      <author><first>Jihyung</first><last>Moon</last></author>
      <pages>13–22</pages>
      <abstract>Social consensus has been established on the severity of online hate speech since it not only causes mental harm to the target, but also gives displeasure to the people who read it. For Korean, the definition and scope of hate speech have been discussed widely in researches, but such considerations were hardly extended to the construction of hate speech corpus. Therefore, we create a Korean online hate speech dataset with concrete annotation guideline to see how real world toxic expressions concern sociolinguistic discussions. This inductive observation reveals that hate speech in online news comments is mainly composed of social bias and toxicity. Furthermore, we check how the final corpus corresponds with the definition and scope of hate speech, and confirm that the overall procedure and outcome is in concurrence with the sociolinguistic discussions.</abstract>
      <url hash="59645c1e">2021.icon-nlp4dh.3</url>
      <bibkey>cho-moon-2021-hate</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>M</fixed-case>ac<fixed-case>BERT</fixed-case>h: Development and Evaluation of a Historically Pre-trained Language Model for <fixed-case>E</fixed-case>nglish (1450-1950)</title>
      <author><first>Enrique</first><last>Manjavacas Arevalo</last></author>
      <author><first>Lauren</first><last>Fonteyn</last></author>
      <pages>23–36</pages>
      <abstract>The new pre-train-then-fine-tune paradigm in Natural made important performance gains accessible to a wider audience. Once pre-trained, deploying a large language model presents comparatively small infrastructure requirements, and offers robust performance in many NLP tasks. The Digital Humanities community has been an early adapter of this paradigm. Yet, a large part of this community is concerned with the application of NLP algorithms to historical texts, for which large models pre-trained on contemporary text may not provide optimal results. In the present paper, we present “MacBERTh”—a transformer-based language model pre-trained on historical English—and exhaustively assess its benefits on a large set of relevant downstream tasks. Our experiments highlight that, despite some differences across target time periods, pre-training on historical language from scratch outperforms models pre-trained on present-day language and later adapted to historical language.</abstract>
      <url hash="2507264c">2021.icon-nlp4dh.4</url>
      <bibkey>manjavacas-arevalo-fonteyn-2021-macberth</bibkey>
    </paper>
    <paper id="5">
      <title>Named Entity Recognition for <fixed-case>F</fixed-case>rench medieval charters</title>
      <author><first>Sergio</first><last>Torres Aguilar</last></author>
      <author><first>Dominique</first><last>Stutzmann</last></author>
      <pages>37–46</pages>
      <abstract>This paper presents the process of annotating and modelling a corpus to automatically detect named entities in medieval charters in French. It introduces a new annotated corpus and a new system which outperforms state-of-the art libraries. Charters are legal documents and among the most important historical sources for medieval studies as they reflect economic and social dynamics as well as the evolution of literacy and writing practices. Automatic detection of named entities greatly improves the access to these unstructured texts and facilitates historical research. The experiments described here are based on a corpus encompassing about 500k words (1200 charters) coming from three charter collections of the 13th and 14th centuries. We annotated the corpus and then trained two state-of-the art NLP libraries for Named Entity Recognition (Spacy and Flair) and a custom neural model (Bi-LSTM-CRF). The evaluation shows that all three models achieve a high performance rate on the test set and a high generalization capacity against two external corpora unseen during training. This paper describes the corpus and the annotation model, and discusses the issues related to the linguistic processing of medieval French and formulaic discourse, so as to interpret the results within a larger historical perspective.</abstract>
      <url hash="313900e0">2021.icon-nlp4dh.5</url>
      <bibkey>torres-aguilar-stutzmann-2021-named</bibkey>
    </paper>
    <paper id="6">
      <title>Processing <fixed-case>M</fixed-case>.<fixed-case>A</fixed-case>. Castrén’s Materials: Multilingual Historical Typed and Handwritten Manuscripts</title>
      <author><first>Niko</first><last>Partanen</last></author>
      <author><first>Jack</first><last>Rueter</last></author>
      <author><first>Khalid</first><last>Alnajjar</last></author>
      <author><first>Mika</first><last>Hämäläinen</last></author>
      <pages>47–54</pages>
      <abstract>The study forms a technical report of various tasks that have been performed on the materials collected and published by Finnish ethnographer and linguist, Matthias Alexander Castrén (1813–1852). The Finno-Ugrian Society is publishing Castrén’s manuscripts as new critical and digital editions, and at the same time different research groups have also paid attention to these materials. We discuss the workflows and technical infrastructure used, and consider how datasets that benefit different computational tasks could be created to further improve the usability of these materials, and also to aid the further processing of similar archived collections. We specifically focus on the parts of the collections that are processed in a way that improves their usability in more technical applications, complementing the earlier work on the cultural and linguistic aspects of these materials. Most of these datasets are openly available in Zenodo. The study points to specific areas where further research is needed, and provides benchmarks for text recognition tasks.</abstract>
      <url hash="82f768fa">2021.icon-nlp4dh.6</url>
      <bibkey>partanen-etal-2021-processing</bibkey>
    </paper>
    <paper id="7">
      <title>Lotte and Annette: A Framework for Finding and Exploring Key Passages in Literary Works</title>
      <author><first>Frederik</first><last>Arnold</last></author>
      <author><first>Robert</first><last>Jäschke</last></author>
      <pages>55–63</pages>
      <abstract>We present an approach that leverages expert knowledge contained in scholarly works to automatically identify key passages in literary works. Specifically, we extend a text reuse detection method for finding quotations, such that our system Lotte can deal with common properties of quotations, for example, ellipses or inaccurate quotations. An evaluation shows that Lotte outperforms four existing approaches. To generate key passages, we combine overlapping quotations from multiple scholarly texts. An interactive website, called Annette, for visualizing and exploring key passages makes the results accessible and explorable.</abstract>
      <url hash="1181a707">2021.icon-nlp4dh.7</url>
      <bibkey>arnold-jaschke-2021-lotte</bibkey>
    </paper>
    <paper id="8">
      <title>Using Referring Expression Generation to Model Literary Style</title>
      <author><first>Nick</first><last>Montfort</last></author>
      <author><first>Ardalan</first><last>SadeghiKivi</last></author>
      <author><first>Joanne</first><last>Yuan</last></author>
      <author><first>Alan Y.</first><last>Zhu</last></author>
      <pages>64–74</pages>
      <abstract>Novels and short stories are not just remarkable because of what events they represent. The narrative style they employ is significant. To understand the specific contributions of different aspects of this style, it is possible to create limited symbolic models of narrating that hold almost all of the narrative discourse constant while varying a single aspect. In this paper we use a new implementation of a system for narrative discourse generation, Curveship, to change how existents at the story level are named. This by itself allows for the telling of the same underlying story in ways that evoke, for instance, a fabular or parable-like mode, the style of narrator Patrick Bateman in Brett Easton Ellis’s American Psycho, and the unusual dialect of Anthony Burgess’s A Clockwork Orange.</abstract>
      <url hash="36f5e40b">2021.icon-nlp4dh.8</url>
      <attachment type="OptionalSupplementaryMaterial" hash="f3e655ed">2021.icon-nlp4dh.8.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>montfort-etal-2021-using</bibkey>
    </paper>
    <paper id="9">
      <title>The concept of nation in nineteenth-century <fixed-case>G</fixed-case>reek fiction through computational literary analysis</title>
      <author><first>Fotini</first><last>Koidaki</last></author>
      <author><first>Despina</first><last>Christou</last></author>
      <author><first>Katerina</first><last>Tiktopoulou</last></author>
      <author><first>Grigorios</first><last>Tsoumakas</last></author>
      <pages>75–84</pages>
      <abstract>How the construction of national consciousness may be captured in the literary production of a whole century? What can the macro-analysis of the 19th-century prose fiction reveal about the formation of the concept of the nation-state of Greece? How could the concept of nationality be detected in literary writing and then interpreted? These are the questions addressed by the research that is published in this paper and which focuses on exploring how the concept of the nation is figured and shaped in 19th-century Greek prose fiction. This paper proposes a methodological approach that combines well-known text mining techniques with computational close reading methods in order to retrieve the nation-related passages and to analyze them linguistically and semantically. The main objective of the paper at hand is to map the frequency and the phraseology of the nation-related references, as well as to explore the phrase patterns in relation to the topic modeling results.</abstract>
      <url hash="2e2fb30e">2021.icon-nlp4dh.9</url>
      <bibkey>koidaki-etal-2021-concept</bibkey>
    </paper>
    <paper id="10">
      <title>Logical Layout Analysis Applied to Historical Newspapers</title>
      <author><first>Nicolas</first><last>Gutehrlé</last></author>
      <author><first>Iana</first><last>Atanassova</last></author>
      <pages>85–94</pages>
      <abstract>In recent years, libraries and archives led important digitisation campaigns that opened the access to vast collections of historical documents. While such documents are often available as XML ALTO documents, they lack information about their logical structure. In this paper, we address the problem of logical layout analysis applied to historical documents. We propose a method which is based on the study of a dataset in order to identify rules that assign logical labels to both block and lines of text from XML ALTO documents. Our dataset contains newspapers in French, published in the first half of the 20th century. The evaluation shows that our methodology performs well for the identification of first lines of paragraphs and text lines, with F1 above 0.9. The identification of titles obtains an F1 of 0.64. This method can be applied to preprocess XML ALTO documents in preparation for downstream tasks, and also to annotate large-scale datasets to train machine learning and deep learning algorithms.</abstract>
      <url hash="6d9512f6">2021.icon-nlp4dh.10</url>
      <bibkey>gutehrle-atanassova-2021-logical</bibkey>
    </paper>
    <paper id="11">
      <title>“Don’t worry, it’s just noise’”: quantifying the impact of files treated as single textual units when they are really collections</title>
      <author><first>Thibault</first><last>Clérice</last></author>
      <pages>95–105</pages>
      <abstract>Literature works may present many autonomous or semi-autonomous units, such as poems for the first or chapter for the second. We make the hypothesis that such cuts in the text’s flow, if not taken care of in the way we process text, have an impact on the application of the distributional hypothesis. We test this hypothesis with a large 20M tokens corpus of Latin works, by using text files as a single unit or multiple “autonomous” units for the analysis of selected words. For groups of rare words and words specific to heavily segmented works, the results show that their semantic space is mostly different between both versions of the corpus. For the 1000 most frequent words of the corpus, variations are important as soon as the window for defining neighborhood is larger or equal to 10 words.</abstract>
      <url hash="092df644">2021.icon-nlp4dh.11</url>
      <bibkey>clerice-2021-dont</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>NLP</fixed-case> in the <fixed-case>DH</fixed-case> pipeline: Transfer-learning to a Chronolect</title>
      <author><first>Aynat</first><last>Rubinstein</last></author>
      <author><first>Avi</first><last>Shmidman</last></author>
      <pages>106–110</pages>
      <abstract>A big unknown in Digital Humanities (DH) projects that seek to analyze previously untouched corpora is the question of how to adapt existing Natural Language Processing (NLP) resources to the specific nature of the target corpus. In this paper, we study the case of Emergent Modern Hebrew (EMH), an under-resourced chronolect of the Hebrew language. The resource we seek to adapt, a diacritizer, exists for both earlier and later chronolects of the language. Given a small annotated corpus of our target chronolect, we demonstrate that applying transfer-learning from either of the chronolects is preferable to training a new model from scratch. Furthermore, we consider just how much annotated data is necessary. For our task, we find that even a minimal corpus of 50K tokens provides a noticeable gain in accuracy. At the same time, we also evaluate accuracy at three additional increments, in order to quantify the gains that can be expected by investing in a larger annotated corpus.</abstract>
      <url hash="b488303e">2021.icon-nlp4dh.12</url>
      <bibkey>rubinstein-shmidman-2021-nlp</bibkey>
    </paper>
    <paper id="13">
      <title>Using Computational Grounded Theory to Understand Tutors’ Experiences in the Gig Economy</title>
      <author><first>Lama</first><last>Alqazlan</last></author>
      <author><first>Rob</first><last>Procter</last></author>
      <author><first>Michael</first><last>Castelle</last></author>
      <pages>111–120</pages>
      <abstract>The introduction of online marketplace platforms has led to the advent of new forms of flexible, on-demand (or ‘gig’) work. Yet, most prior research concerning the experience of gig workers examines delivery or crowdsourcing platforms, while the experience of the large numbers of workers who undertake educational labour in the form of tutoring gigs remains understudied. To address this, we use a computational grounded theory approach to analyse tutors’ discussions on Reddit. This approach consists of three phases including data exploration, modelling and human-centred interpretation. We use both validation and human evaluation to increase the trustworthiness and reliability of the computational methods. This paper is a work in progress and reports on the first of the three phases of this approach.</abstract>
      <url hash="d6992d49">2021.icon-nlp4dh.13</url>
      <bibkey>alqazlan-etal-2021-using</bibkey>
    </paper>
    <paper id="14">
      <title>Can Domain Pre-training Help Interdisciplinary Researchers from Data Annotation Poverty? A Case Study of Legal Argument Mining with <fixed-case>BERT</fixed-case>-based Transformers</title>
      <author><first>Gechuan</first><last>Zhang</last></author>
      <author><first>David</first><last>Lillis</last></author>
      <author><first>Paul</first><last>Nulty</last></author>
      <pages>121–130</pages>
      <abstract>Interdisciplinary Natural Language Processing (NLP) research traditionally suffers from the requirement for costly data annotation. However, transformer frameworks with pre-training have shown their ability on many downstream tasks including digital humanities tasks with limited small datasets. Considering the fact that many digital humanities fields (e.g. law) feature an abundance of non-annotated textual resources, and the recent achievements led by transformer models, we pay special attention to whether domain pre-training will enhance transformer’s performance on interdisciplinary tasks and how. In this work, we use legal argument mining as our case study. This aims to automatically identify text segments with particular linguistic structures (i.e., arguments) from legal documents and to predict the reasoning relations between marked arguments. Our work includes a broad survey of a wide range of BERT variants with different pre-training strategies. Our case study focuses on: the comparison of general pre-training and domain pre-training; the generalisability of different domain pre-trained transformers; and the potential of merging general pre-training with domain pre-training. We also achieve better results than the current transformer baseline in legal argument mining.</abstract>
      <url hash="cf668c1d">2021.icon-nlp4dh.14</url>
      <bibkey>zhang-etal-2021-domain</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>J</fixed-case>apanese Beauty Marketing on Social Media: Critical Discourse Analysis Meets <fixed-case>NLP</fixed-case></title>
      <author><first>Emily</first><last>Öhman</last></author>
      <author><first>Amy Gracy</first><last>Metcalfe</last></author>
      <pages>131–137</pages>
      <abstract>This project is a pilot study intending to combine traditional corpus linguistics, Natural Language Processing, critical discourse analysis, and digital humanities to gain an up-to-date understanding of how beauty is being marketed on social media, specifically Instagram, to followers. We use topic modeling combined with critical discourse analysis and NLP tools for insights into the “Japanese Beauty Myth” and show an overview of the dataset that we make publicly available.</abstract>
      <url hash="1d231521">2021.icon-nlp4dh.15</url>
      <bibkey>ohman-metcalfe-2021-japanese</bibkey>
    </paper>
    <paper id="16">
      <title>Text Zoning of Theater Reviews: How Different are Journalistic from Blogger Reviews?</title>
      <author><first>Mylene</first><last>Maignant</last></author>
      <author><first>Thierry</first><last>Poibeau</last></author>
      <author><first>Gaëtan</first><last>Brison</last></author>
      <pages>138–143</pages>
      <abstract>This paper aims at modeling the structure of theater reviews based on contemporary London performances by using text zoning. Text zoning consists in tagging sentences so as to reveal text structure. More than 40 000 theater reviews going from 2010 to 2020 were collected to analyze two different types of reception (journalistic vs digital). We present our annotation scheme and the classifiers used to perform the text zoning task, aiming at tagging reviews at the sentence level. We obtain the best results using the random forest algorithm, and show that this approach makes it possible to give a first insight of the similarities and differences between our two subcorpora.</abstract>
      <url hash="581ec7fa">2021.icon-nlp4dh.16</url>
      <bibkey>maignant-etal-2021-text</bibkey>
    </paper>
    <paper id="17">
      <title>Word Sense Induction with Attentive Context Clustering</title>
      <author><first>Moshe</first><last>Stekel</last></author>
      <author><first>Amos</first><last>Azaria</last></author>
      <author><first>Shai</first><last>Gordin</last></author>
      <pages>144–151</pages>
      <abstract>In this paper, we present ACCWSI (Attentive Context Clustering WSI), a method for Word Sense Induction, suitable for languages with limited resources. Pretrained on a small corpus and given an ambiguous word (query word) and a set of excerpts that contain it, ACCWSI uses an attention mechanism for generating context-aware embeddings, distinguishing between the different senses assigned to the query word. These embeddings are then clustered to provide groups of main common uses of the query word. This method demonstrates practical applicability for shedding light on the meanings of ambiguous words in ancient languages, such as Classical Hebrew.</abstract>
      <url hash="efe83dcb">2021.icon-nlp4dh.17</url>
      <bibkey>stekel-etal-2021-word</bibkey>
    </paper>
    <paper id="18">
      <title>Transferring Modern Named Entity Recognition to the Historical Domain: How to Take the Step?</title>
      <author><first>Baptiste</first><last>Blouin</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <author><first>Jeremy</first><last>Auguste</last></author>
      <author><first>Christian</first><last>Henriot</last></author>
      <pages>152–162</pages>
      <abstract>Named entity recognition is of high interest to digital humanities, in particular when mining historical documents. Although the task is mature in the field of NLP, results of contemporary models are not satisfactory on challenging documents corresponding to out-of-domain genres, noisy OCR output, or old-variants of the target language. In this paper we study how model transfer methods, in the context of the aforementioned challenges, can improve historical named entity recognition according to how much effort is allocated to describing the target data, manually annotating small amounts of texts, or matching pre-training resources. In particular, we explore the situation where the class labels, as well as the quality of the documents to be processed, are different in the source and target domains. We perform extensive experiments with the transformer architecture on the LitBank and HIPE historical datasets, with different annotation schemes and character-level noise. They show that annotating 250 sentences can recover 93% of the full-data performance when models are pre-trained, that the choice of self-supervised and target-task pre-training data is crucial in the zero-shot setting, and that OCR errors can be handled by simulating noise on pre-training data and resorting to recent character-aware transformers.</abstract>
      <url hash="853d34d8">2021.icon-nlp4dh.18</url>
      <bibkey>blouin-etal-2021-transferring</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>TFW</fixed-case>2<fixed-case>V</fixed-case>: An Enhanced Document Similarity Method for the Morphologically Rich <fixed-case>F</fixed-case>innish Language</title>
      <author><first>Quan</first><last>Duong</last></author>
      <author><first>Mika</first><last>Hämäläinen</last></author>
      <author><first>Khalid</first><last>Alnajjar</last></author>
      <pages>163–172</pages>
      <abstract>Measuring the semantic similarity of different texts has many important applications in Digital Humanities research such as information retrieval, document clustering and text summarization. The performance of different methods depends on the length of the text, the domain and the language. This study focuses on experimenting with some of the current approaches to Finnish, which is a morphologically rich language. At the same time, we propose a simple method, TFW2V, which shows high efficiency in handling both long text documents and limited amounts of data. Furthermore, we design an objective evaluation method which can be used as a framework for benchmarking text similarity approaches.</abstract>
      <url hash="56b30209">2021.icon-nlp4dh.19</url>
      <bibkey>duong-etal-2021-tfw2v</bibkey>
    </paper>
    <paper id="20">
      <title>Did You Enjoy the Last Supper? An Experimental Study on Cross-Domain <fixed-case>NER</fixed-case> Models for the Art Domain</title>
      <author><first>Alejandro</first><last>Sierra-Múnera</last></author>
      <author><first>Ralf</first><last>Krestel</last></author>
      <pages>173–182</pages>
      <abstract>Named entity recognition (NER) is an important task that constitutes the basis for multiple downstream natural language processing tasks. Traditional machine learning approaches for NER rely on annotated corpora. However, these are only largely available for standard domains, e.g., news articles. Domain-specific NER often lacks annotated training data and therefore two options are of interest: expensive manual annotations or transfer learning. In this paper, we study a selection of cross-domain NER models and evaluate them for use in the art domain, particularly for recognizing artwork titles in digitized art-historic documents. For the evaluation of the models, we employ a variety of source domain datasets and analyze how each source domain dataset impacts the performance of the different models for our target domain. Additionally, we analyze the impact of the source domain’s entity types, looking for a better understanding of how the transfer learning models adapt different source entity types into our target entity types.</abstract>
      <url hash="d7069a59">2021.icon-nlp4dh.20</url>
      <bibkey>sierra-munera-krestel-2021-enjoy</bibkey>
    </paper>
    <paper id="21">
      <title>An Exploratory Study on Temporally Evolving Discussion around Covid-19 using Diachronic Word Embeddings</title>
      <author><first>Avinash</first><last>Tulasi</last></author>
      <author><first>Asanobu</first><last>Kitamoto</last></author>
      <author><first>Ponnurangam</first><last>Kumaraguru</last></author>
      <author><first>Arun Balaji</first><last>Buduru</last></author>
      <pages>183–190</pages>
      <abstract>Covid 19 has seen the world go into a lock down and unconventional social situations throughout. During this time, the world saw a surge in information sharing around the pandemic and the topics shared in the time were diverse. People’s sentiments have changed during this period. Given the wide spread usage of Online Social Networks (OSN) and support groups, the user sentiment is well reflected in online discussions. In this work, we aim to show the topics under discussion, evolution of discussions, change in user sentiment during the pandemic. Alongside which, we also demonstrate the possibility of exploratory analysis to find pressing topics, change in perception towards the topics and ways to use the knowledge extracted from online discussions. For our work we employ Diachronic Word embeddings which capture the change in word usage over time. With the help of analysis from temporal word usages, we show the change in people’s option on covid-19 from being a conspiracy, to the post-covid topics that surround vaccination.</abstract>
      <url hash="2de71274">2021.icon-nlp4dh.21</url>
      <bibkey>tulasi-etal-2021-exploratory</bibkey>
    </paper>
  </volume>
  <volume id="genderbias" ingest-date="2022-09-06">
    <meta>
      <booktitle>Proceedings of the 18th International Conference on Natural Language Processing: Shared Task on Multilingual Gender Biased and Communal Language Identification</booktitle>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Siddharth</first><last>Singh</last></editor>
      <editor><first>Enakshi</first><last>Nandi</last></editor>
      <editor><first>Shyam</first><last>Ratan</last></editor>
      <editor><first>Laishram Niranjana</first><last>Devi</last></editor>
      <editor><first>Bornini</first><last>Lahiri</last></editor>
      <editor><first>Akanksha</first><last>Bansal</last></editor>
      <editor><first>Akash</first><last>Bhagat</last></editor>
      <editor><first>Yogesh</first><last>Dawer</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>NIT Silchar</address>
      <month>December</month>
      <year>2021</year>
      <url hash="fdbbcd36">2021.icon-genderbias</url>
    </meta>
    <frontmatter>
      <url hash="b4917594">2021.icon-genderbias.0</url>
      <bibkey>icon-2021-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Multilingual Gender Biased and Communal Language Identification Task at <fixed-case>ICON</fixed-case>-2021</title>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Shyam</first><last>Ratan</last></author>
      <author><first>Siddharth</first><last>Singh</last></author>
      <author><first>Enakshi</first><last>Nandi</last></author>
      <author><first>Laishram Niranjana</first><last>Devi</last></author>
      <author><first>Akash</first><last>Bhagat</last></author>
      <author><first>Yogesh</first><last>Dawer</last></author>
      <author><first>Bornini</first><last>Lahiri</last></author>
      <author><first>Akanksha</first><last>Bansal</last></author>
      <pages>1–12</pages>
      <abstract>This paper presents the findings of the ICON-2021 shared task on Multilingual Gender Biased and Communal Language Identification, which aims to identify aggression, gender bias, and communal bias in data presented in four languages: Meitei, Bangla, Hindi and English. The participants were presented the option of approaching the task as three separate classification tasks or a multi-label classification task or a structured classification task. If approached as three separate classification tasks, the task includes three sub-tasks: aggression identification (sub-task A), gender bias identification (sub-task B), and communal bias identification (sub-task C). For this task, the participating teams were provided with a total dataset of approximately 12,000, with 3,000 comments across each of the four languages, sourced from popular social media sites such as YouTube, Twitter, Facebook and Telegram and the the three labels presented as a single tuple. For the test systems, approximately 1,000 comments were provided in each language for every sub-task. We attracted a total of 54 registrations in the task, out of which 11 teams submitted their test runs. The best system obtained an overall instance-F1 of 0.371 in the multilingual test set (it was simply a combined test set of the instances in each individual language). In the individual sub-tasks, the best micro f1 scores are 0.539, 0.767 and 0.834 respectively for each of the sub-task A, B and C. The best overall, averaged micro f1 is 0.713. The results show that while systems have managed to perform reasonably well in individual sub-tasks, especially gender bias and communal bias tasks, it is substantially more difficult to do a 3-class classification of aggression level and even more difficult to build a system that correctly classifies everything right. It is only in slightly over 1/3 of the instances that most of the systems predicted the correct class across the board, despite the fact that there was a significant overlap across the three sub-tasks.</abstract>
      <url hash="7ea068e8">2021.icon-genderbias.1</url>
      <bibkey>kumar-etal-2021-comma</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>T</fixed-case>eam_<fixed-case>BUDDI</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Exploring Individual and Joint Modelling Approaches for Detecting Aggression, Communal Bias and Gender Bias</title>
      <author><first>Anand</first><last>Subramanian</last></author>
      <author><first>Mukesh</first><last>Reghu</last></author>
      <author><first>Sriram</first><last>Rajkumar</last></author>
      <pages>13–20</pages>
      <abstract>The ComMA@ICON 2021 Shared Task involved identifying the level of aggression and identifying gender bias and communal bias from texts in various languages from the domain of social media. In this paper, we present the description and analyses of systems we implemented towards these tasks. We built systems utilizing Transformer-based models, experimented by individually and jointly modelling these tasks, and investigated the performance of a feature engineering method in conjunction with a joint modelling approach. We demonstrate that the joint modelling approaches outperform the individual modelling approach in most cases.</abstract>
      <url hash="d9e79a7f">2021.icon-genderbias.2</url>
      <bibkey>subramanian-etal-2021-team</bibkey>
    </paper>
    <paper id="3">
      <title>Hypers at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Modelling Aggressive, Gender Bias and Communal Bias Identification</title>
      <author><first>Sean</first><last>Benhur</last></author>
      <author><first>Roshan</first><last>Nayak</last></author>
      <author><first>Kanchana</first><last>Sivanraju</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Cn</first><last>Subalalitha</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>21–25</pages>
      <abstract>Due to the exponential increasing reach of social media, it is essential to focus on its negative aspects as it can potentially divide society and incite people into violence. In this paper, we present our system description of work on the shared task ComMA@ICON, where we have to classify how aggressive the sentence is and if the sentence is gender-biased or communal biased. These three could be the primary reasons to cause significant problems in society. Our approach utilizes different pretrained models with Attention and mean pooling methods. We were able to get Rank 1 with 0.253 Instance F1 score on Bengali, Rank 2 with 0.323 Instance F1 score on multilingual set, Rank 4 with 0.129 Instance F1 score on meitei and Rank 5 with 0.336 Instance F1 score on Hindi. The source code and the pretrained models of this work can be found here.</abstract>
      <url hash="ea21e18a">2021.icon-genderbias.3</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ec1486f6">2021.icon-genderbias.3.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>benhur-etal-2021-hypers</bibkey>
    </paper>
    <paper id="4">
      <title>Beware Haters at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Sequence and Ensemble Classifiers for Aggression, Gender Bias and Communal Bias Identification in <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Deepakindresh</first><last>Gandhi</last></author>
      <author><first>Aakash</first><last>Ambalavanan</last></author>
      <author><first>Avireddy</first><last>Rohan</last></author>
      <author><first>Radhika</first><last>Selvamani</last></author>
      <pages>26–34</pages>
      <abstract>Aggressive and hate-filled messages are prevalent on the internet more than ever. These messages are being targeted against a person or an event online and making the internet a more hostile environment. Since this issue is widespread across many users and is not only limited to one language, there is a need for automated models with multilingual capabilities to detect such hostile messages on the online platform. In this paper, the performance of our classifiers is described in the Shared Task on Multilingual Gender Biased and Communal Language Identification at ICON 2021. Our team “Beware Haters” took part in Hindi, Bengali, Meitei, and Multilingual tasks. Our team used various models like Random Forest, Logistic Regression, Bidirectional Long Short Term Memory, and an ensemble model. Model interpretation tool LIME was used before integrating the models. The instance F1 score of our best performing models for Hindi, Bengali, Meitei, and Multilingual tasks are 0.289, 0.292, 0.322, and 0.294 respectively.</abstract>
      <url hash="2515d570">2021.icon-genderbias.4</url>
      <bibkey>gandhi-etal-2021-beware</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>DEL</fixed-case>ab@<fixed-case>IIITSM</fixed-case> at <fixed-case>ICON</fixed-case>-2021 Shared Task: Identification of Aggression and Biasness Using Decision Tree</title>
      <author><first>Maibam</first><last>Debina</last></author>
      <author><first>Navanath</first><last>Saharia</last></author>
      <pages>35–40</pages>
      <abstract>This paper presents our system description on participation in ICON-2021 Shared Task sub-task 1 on multilingual gender-biased and communal language identification as team name: DELab@IIITSM. We have participated in two language-specific Meitei, Hindi, and one multi-lingualMeitei, Hindi, and Bangla with English code-mixed languages identification task. Our method includes well design pre-processing phase based on the dataset, the frequency-based feature extraction technique TF-IDF which creates the feature vector for each instance using(Decision Tree). We obtained weights are 0.629, 0.625, and 0.632 as the overall micro F1 score for the Hindi, Meitei, and multilingual datasets.</abstract>
      <url hash="7537af5e">2021.icon-genderbias.5</url>
      <attachment type="OptionalSupplementaryMaterial" hash="408b33c9">2021.icon-genderbias.5.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>debina-saharia-2021-delab</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>LUC</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>-2021 Shared Task: Multilingual Gender Biased and Communal Language Identification without Using Linguistic Features</title>
      <author><first>Rodrigo</first><last>Cuéllar-Hidalgo</last></author>
      <author><first>Julio de Jesús</first><last>Guerrero-Zambrano</last></author>
      <author><first>Dominic</first><last>Forest</last></author>
      <author><first>Gerardo</first><last>Reyes-Salgado</last></author>
      <author><first>Juan-Manuel</first><last>Torres-Moreno</last></author>
      <pages>41–45</pages>
      <abstract>This work aims to evaluate the ability that both probabilistic and state-of-the-art vector space modeling (VSM) methods provide to well known machine learning algorithms to identify social network documents to be classified as aggressive, gender biased or communally charged. To this end, an exploratory stage was performed first in order to find relevant settings to test, i.e. by using training and development samples, we trained multiple algorithms using multiple vector space modeling and probabilistic methods and discarded the less informative configurations. These systems were submitted to the competition of the ComMA@ICON’21 Workshop on Multilingual Gender Biased and Communal Language Identification.</abstract>
      <url hash="03083f34">2021.icon-genderbias.6</url>
      <bibkey>cuellar-hidalgo-etal-2021-luc</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>ARGUABLY</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Detection of Multilingual Aggressive, Gender Biased, and Communally Charged Tweets Using Ensemble and Fine-Tuned <fixed-case>I</fixed-case>ndic<fixed-case>BERT</fixed-case></title>
      <author><first>Guneet</first><last>Kohli</last></author>
      <author><first>Prabsimran</first><last>Kaur</last></author>
      <author><first>Jatin</first><last>Bedi</last></author>
      <pages>46–52</pages>
      <abstract>The proliferation in Social Networking has increased offensive language, aggression, and hate-speech detection, which has drawn the focus of the NLP community. However, people’s difference in perception makes it difficult to distinguish between acceptable content and aggressive/hateful content, thus making it harder to create an automated system. In this paper, we propose multi-class classification techniques to identify aggressive and offensive language used online. Two main approaches have been developed for the classification of data into aggressive, gender-biased, and communally charged. The first approach is an ensemble-based model comprising of XG-Boost, LightGBM, and Naive Bayes applied on vectorized English data. The data used was obtained using an Indic Transliteration on the original data comprising of Meitei, Bangla, Hindi, and English language. The second approach is a BERT-based architecture used to detect misogyny and aggression. The proposed model employs IndicBERT Embeddings to define contextual understanding. The results of the models are validated on the ComMA v 0.2 dataset.</abstract>
      <url hash="a6b46313">2021.icon-genderbias.7</url>
      <bibkey>kohli-etal-2021-arguably</bibkey>
    </paper>
    <paper id="8">
      <title>Sdutta at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: A <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> Model for Hate Detection</title>
      <author><first>Sandip</first><last>Dutta</last></author>
      <author><first>Utso</first><last>Majumder</last></author>
      <author><first>Sudip</first><last>Naskar</last></author>
      <pages>53–57</pages>
      <abstract>In today’s world, online activity and social media are facing an upsurge of cases of aggression, gender-biased comments and communal hate. In this shared task, we used a CNN-LSTM hybrid method to detect aggression, misogynistic and communally charged content in social media texts. First, we employ text cleaning and convert the text into word embeddings. Next we proceed to our CNN-LSTM based model to predict the nature of the text. Our model achieves 0.288, 0.279, 0.294 and 0.335 Overall Micro F1 Scores in multilingual, Meitei, Bengali and Hindi datasets, respectively, on the 3 prediction labels.</abstract>
      <url hash="f7c61e91">2021.icon-genderbias.8</url>
      <bibkey>dutta-etal-2021-sdutta</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>MUCIC</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Multilingual Gender Biased and Communal Language Identification Using N-grams and Multilingual Sentence Encoders</title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Oxana</first><last>Vitman</last></author>
      <author><first>Hosahalli Lakshmaiah</first><last>Shashirekha</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <author><first>Alexander</first><last>Gelbukh</last></author>
      <pages>58–63</pages>
      <abstract>Social media analytics are widely being explored by researchers for various applications. Prominent among them are identifying and blocking abusive contents especially targeting individuals and communities, for various reasons. The increasing abusive contents and the increasing number of users on social media demands automated tools to detect and filter the abusive contents as it is highly impossible to handle this manually. To address the challenges of detecting abusive contents, this paper describes the approaches proposed by our team MUCIC for Multilingual Gender Biased and Communal Language Identification shared task (ComMA@ICON) at International Conference on Natural Language Processing (ICON) 2021. This shared task dataset consists of code-mixed multi-script texts in Meitei, Bangla, Hindi as well as in Multilingual (a combination of Meitei, Bangla, Hindi, and English). The shared task is modeled as a multi-label Text Classification (TC) task combining word and char n-grams with vectors obtained from Multilingual Sentence Encoder (MSE) to train the Machine Learning (ML) classifiers using Pre-aggregation and Post-aggregation of labels. These approaches obtained the highest performance in the shared task for Meitei, Bangla, and Multilingual texts with instance-F1 scores of 0.350, 0.412, and 0.380 respectively using Pre-aggregation of labels.</abstract>
      <url hash="0fb68d24">2021.icon-genderbias.9</url>
      <bibkey>balouchzahi-etal-2021-mucic</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>MUM</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case>: Multilingual Gender Biased and Communal Language Identification Using Supervised Learning Approaches</title>
      <author><first>Asha</first><last>Hegde</last></author>
      <author><first>Mudoor Devadas</first><last>Anusha</last></author>
      <author><first>Sharal</first><last>Coelho</last></author>
      <author><first>Hosahalli Lakshmaiah</first><last>Shashirekha</last></author>
      <pages>64–69</pages>
      <abstract>Due to the rapid rise of social networks and micro-blogging websites, communication between people from different religion, caste, creed, cultural and psychological backgrounds has become more direct leading to the increase in cyber conflicts between people. This in turn has given rise to more and more hate speech and usage of abusive words to the point that it has become a serious problem creating negative impacts on the society. As a result, it is imperative to identify and filter such content on social media to prevent its further spread and the damage it is going to cause. Further, filtering such huge data requires automated tools since doing it manually is labor intensive and error prone. Added to this is the complex code-mixed and multi-scripted nature of social media text. To address the challenges of abusive content detection on social media, in this paper, we, team MUM, propose Machine Learning (ML) and Deep Learning (DL) models submitted to Multilingual Gender Biased and Communal Language Identification (ComMA@ICON) shared task at International Conference on Natural Language Processing (ICON) 2021. Word uni-grams, char n-grams, and emoji vectors are combined as features to train a ML Elastic-net regression model and multi-lingual Bidirectional Encoder Representations from Transformers (mBERT) is fine-tuned for a DL model. Out of the two, fine-tuned mBERT model performed better with an instance-F1 score of 0.326, 0.390, 0.343, 0.359 for Meitei, Bangla, Hindi, Multilingual texts respectively.</abstract>
      <url hash="fabc2a7a">2021.icon-genderbias.10</url>
      <bibkey>hegde-etal-2021-mum</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>BFCAI</fixed-case> at <fixed-case>C</fixed-case>om<fixed-case>MA</fixed-case>@<fixed-case>ICON</fixed-case> 2021: Support Vector Machines for Multilingual Gender Biased and Communal Language Identification</title>
      <author><first>Fathy</first><last>Elkazzaz</last></author>
      <author><first>Fatma</first><last>Sakr</last></author>
      <author><first>Rasha</first><last>Orban</last></author>
      <author><first>Hamada</first><last>Nayel</last></author>
      <pages>70–74</pages>
      <abstract>This paper presents the system that has been submitted to the multilingual gender biased and communal language identification shared task by BFCAI team. The proposed model used Support Vector Machines (SVMs) as a classification algorithm. The features have been extracted using TF/IDF model with unigram and bigram. The proposed model is very simple and there are no external resources are needed to build the model.</abstract>
      <url hash="8d106b93">2021.icon-genderbias.11</url>
      <bibkey>elkazzaz-etal-2021-bfcai</bibkey>
    </paper>
  </volume>
</collection>
